{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3f68150db0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=123)\n",
    "parser.add_argument('--method', type=str, default='CER', choices=[\n",
    "    'CER', 'REF', 'SLL', 'SLL_G'\n",
    "])\n",
    "parser.add_argument('--budget_pct', type=float, default=0.25)\n",
    "parser.add_argument('--g0_method', type=str, default='random', choices=[\n",
    "  'random', # randomly distribution of g0\n",
    "  'bias', # a random class has a 3x higher likelihood of being in g0\n",
    "  'large_cluster', # a random node and [g0_size] of its neighbors are in g0\n",
    "  # 'many_clusters', # 10 random nodes and [g0_size] of their neighbors are in g0\n",
    "  ])\n",
    "parser.add_argument('--g0_size', type=float, default=0.2)\n",
    "parser.add_argument('--lr', type=float, default=0.1)\n",
    "parser.add_argument('--T_s', type=int, default=-1)\n",
    "parser.add_argument('--T_u', type=int, default=0)\n",
    "parser.add_argument('--dataset', type=str, default='cora', choices=[\n",
    "    'Cora', 'Cora-ML', 'Citeseer', 'Pubmed', 'Polblogs', 'ACM', 'BlogCatalog', 'Flickr', 'UAI'\n",
    "])\n",
    "parser.add_argument('--ptb_rate', type=float, default=0.25)\n",
    "\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "adj, feat, labels, train_mask, val_mask, test_mask = utils.load_data(args.dataset, args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.data import Dataset\n",
    "from deeprobust.graph.utils import preprocess\n",
    "\n",
    "clean_dataset = Dataset(root='./tmp/', name=args.dataset, seed=args.seed)\n",
    "adj, feat, labels = clean_dataset.adj, clean_dataset.features, clean_dataset.labels\n",
    "adj, feat, labels = preprocess(adj, feat, labels, preprocess_adj=False, device='cpu') # conver to tensor\n",
    "idx_train, idx_val, idx_test = clean_dataset.idx_train, clean_dataset.idx_val, clean_dataset.idx_test\n",
    "# adj = torch.tensor(clean_dataset.adj.toarray(), dtype=torch.float).to(device)\n",
    "# feat = torch.tensor(clean_dataset.features.toarray(), dtype=torch.float).to(device)\n",
    "# label = torch.tensor(clean_dataset.labels, dtype=torch.long).to(device)\n",
    "\n",
    "train_mask = torch.zeros([adj.shape[0]], dtype=torch.bool)  \n",
    "train_mask[idx_train] = 1\n",
    "test_mask = torch.zeros([adj.shape[0]], dtype=torch.bool)  \n",
    "test_mask[idx_test] = 1\n",
    "val_mask = torch.zeros([adj.shape[0]], dtype=torch.bool)  \n",
    "val_mask[idx_val] = 1\n",
    "\n",
    "num_samples = 2560\n",
    "subgraph_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "T_s = T_u = torch.tensor([0])\n",
    "\n",
    "if args.T_s == -1: T_s = labels\n",
    "else:\n",
    "    T_s = utils.binary(feat[:,args.T_s].clone())\n",
    "    feat[:,args.T_s] = 0\n",
    "\n",
    "if args.T_u == -1: T_u = labels\n",
    "else:\n",
    "    T_u = utils.binary(feat[:,args.T_u].clone())\n",
    "    feat[:,args.T_u] = 0\n",
    "\n",
    "# T_s = T_s.to(device)\n",
    "# T_u = T_u.to(device)\n",
    "# import torch.nn.functional as F\n",
    "# fs = F.normalize(feat, p=1, dim=1).sum(axis=1)\n",
    "# T_u = (fs > fs.median()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0 with method: random\n",
      "G0 size: 487\n",
      "G0 pct: 19.60%\n"
     ]
    }
   ],
   "source": [
    "g0_size = int(args.g0_size * adj.shape[0])\n",
    "g0 = utils.get_g0(g0_size, adj, method=args.g0_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0 size: 519\n",
      "G0 pct: 20.89%\n"
     ]
    }
   ],
   "source": [
    "# Designate g0 ===================================\n",
    "\n",
    "def get_clusters(num_roots: int, max_hops: int, target_size: int) -> torch.Tensor:\n",
    "  root_nodes = torch.rand(adj.shape[0]).topk(num_roots).indices\n",
    "\n",
    "  for hop in range(max_hops):\n",
    "    newNodes = adj[root_nodes].nonzero().t()[1]\n",
    "    root_nodes = torch.cat((root_nodes, newNodes))\n",
    "    root_nodes = torch.unique(root_nodes)\n",
    "    if root_nodes.shape[0] >= target_size:\n",
    "      break\n",
    "\n",
    "  g0 = torch.zeros(adj.shape[0])\n",
    "  g0[root_nodes[:target_size]] = 1\n",
    "  g0 = g0.bool()\n",
    "  return g0\n",
    "\n",
    "g0 = torch.tensor([0])\n",
    "if args.g0_method == 'many_clusters': # 10 nodes and their neighbors\n",
    "  g0 = get_clusters(10, 10, g0_size)\n",
    "elif args.g0_method == 'large_cluster': # 1 node and its neighbors\n",
    "  g0 = get_clusters(1, 10, g0_size)\n",
    "elif args.g0_method == 'random': # g0 is random/bias\n",
    "  g0_probs = torch.ones(adj.shape[0])\n",
    "  g0_probs = g0_probs * (g0_size / g0_probs.sum())\n",
    "  g0_probs.clamp_(0, 1)\n",
    "  g0 = torch.bernoulli(g0_probs).bool()\n",
    "elif args.g0_method == 'bias': # g0 is skewed toward a class by factor of 3\n",
    "  bias = torch.randint(0, int(labels.max()) + 1, [1]).item()\n",
    "  print(f'G0 class bias: {bias}')\n",
    "  g0_probs = torch.ones(adj.shape[0])\n",
    "  g0_probs[labels == bias] = 3\n",
    "  g0_probs = g0_probs * (g0_size / g0_probs.sum())\n",
    "  g0_probs.clamp_(0, 1)\n",
    "  g0 = torch.bernoulli(g0_probs).bool()\n",
    "\n",
    "print(f'G0 size: {g0.sum().item()}')\n",
    "print(f'G0 pct: {g0.sum().item() / adj.shape[0]:.2%}')\n",
    "\n",
    "# g0 = g0.cpu()\n",
    "gX = ~g0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def scale(M: torch.Tensor, epsilon: int, patience=5) -> torch.Tensor:\n",
    "    if M.abs().sum() == 0: return M\n",
    "    \n",
    "    for i in range(patience): # Maximum attempts\n",
    "        if abs(epsilon / M.abs().sum() - 1) < 0.1: return M.clamp(-1, 1) # Stop with early convergence\n",
    "        M = (M * (epsilon / M.abs().sum())).clamp(-1, 1)\n",
    "\n",
    "    return M.clamp(-1, 1)\n",
    "\n",
    "def discretize(M: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.bernoulli(M.abs().clamp(0, 1))\n",
    "\n",
    "def truncate(M: torch.Tensor, A: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Truncates values in M such that only:\n",
    "    1. positive values exist in M corresponding to non-existing edges\n",
    "    2. negative values exist in M corresponding to alread existing edges\n",
    "    \"\"\"\n",
    "    assert M.shape == A.shape\n",
    "    negative_vals = (M * A).clamp(max=0)\n",
    "    positive_vals = (M * (1-A)).clamp(min=0)\n",
    "    return positive_vals + negative_vals\n",
    "\n",
    "def xor(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n",
    "    return (A + B) - torch.mul(A * B, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, A, T, g, train_mask, val_mask, device='cpu'):\n",
    "    X = X.to(device)\n",
    "    A = A.to(device)\n",
    "    θ = GCN(nfeat=X.shape[1], nclass=T.max().item()+1, nhid=32, device=device).to(device)\n",
    "    masked = train_mask.clone()\n",
    "    masked[g] = 0\n",
    "    θ.fit(X, A, T, masked, val_mask, train_iters=100)\n",
    "    pred = θ(X, A).cpu()\n",
    "    result = pred.argmax(1) == T\n",
    "    acc_g0 = result[g].sum().item() / g.sum().item()\n",
    "    acc_gX = result[~g].sum().item() / (~g).sum().item()\n",
    "    print(f\"G0: {acc_g0:.2%}\")\n",
    "    print(f\"GX: {acc_gX:.2%}\")\n",
    "    return (acc_g0, acc_gX)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CER(A: torch.Tensor, g0: torch.Tensor) -> torch.Tensor:\n",
    "    A = A.cpu()\n",
    "    g0 = g0.cpu()\n",
    "    A[:, g0] = 0\n",
    "    A[g0, :] = 0\n",
    "    return A\n",
    "\n",
    "def REF(A: torch.Tensor, g0: torch.Tensor, ε: int) -> torch.Tensor:\n",
    "    noise = torch.zeros_like(A)\n",
    "    noise[g0, :] = 1\n",
    "    noise[:, gX] = 0\n",
    "    noise *= 2 * ε / noise.sum()\n",
    "    noise = torch.bernoulli(noise.clamp(0, 1))\n",
    "    return xor(A, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 12.72%\n",
      "GX: 79.25%\n",
      "G0: 100.00%\n",
      "GX: 100.00%\n",
      "G0: 18.69%\n",
      "GX: 79.09%\n",
      "G0: 100.00%\n",
      "GX: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locked_adj = CER(adj, g0)\n",
    "evaluate(feat, locked_adj, T_s, g0, train_mask, val_mask, device)\n",
    "evaluate(feat, locked_adj, T_u, g0, train_mask, val_mask, device)\n",
    "\n",
    "budget = (adj.shape[0]) * args.budget_pct\n",
    "locked_adj = REF(adj, g0, budget)\n",
    "evaluate(feat, locked_adj, T_s, g0, train_mask, val_mask, device)\n",
    "evaluate(feat, locked_adj, T_u, g0, train_mask, val_mask, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.01it/s, loss=93.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 37.96%\n",
      "GX: 75.13%\n",
      "G0: 99.42%\n",
      "GX: 99.39%\n"
     ]
    }
   ],
   "source": [
    "from deeprobust.graph.defense import GCN\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def SLL(\n",
    "        A: torch.Tensor, \n",
    "        X:torch.Tensor, \n",
    "        g0: torch.Tensor, \n",
    "        T_s: torch.Tensor, \n",
    "        T_u: torch.Tensor, \n",
    "        ε: int,\n",
    "        epochs: int,\n",
    "        lr: float,\n",
    "        train_mask: torch.Tensor,\n",
    "        val_mask: torch.Tensor,\n",
    "        surrogate_lr=1e-2,\n",
    "        device='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    T_s is sensitive classification task\n",
    "    T_u is utility classification task\n",
    "    g0 is array of boolean representing protected nodes.\n",
    "    \"\"\"\n",
    "    gX = ~g0\n",
    "    X = X.to(device)\n",
    "    T_s = T_s.to(device)\n",
    "    T_u = T_u.to(device)\n",
    "    A = A.to(device)\n",
    "\n",
    "    M = torch.zeros_like(A).float().to(device)\n",
    "    θ_s = GCN(nfeat=X.shape[1], nclass=T_s.max().item()+1, nhid=32, lr=surrogate_lr, device=device).to(device)\n",
    "    θ_u = GCN(nfeat=X.shape[1], nclass=T_u.max().item()+1, nhid=32, lr=surrogate_lr, device=device).to(device)\n",
    "\n",
    "    t = tqdm(range(epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    A_p = torch.zeros_like(A).to(device).requires_grad_(True) # Initialize modified adj\n",
    "\n",
    "    for epoch in t:\n",
    "        # A_p = xor(A, discretize(M, ε)).to(device).requires_grad_(True) # To clear graident of modified adj\n",
    "        L = 0\n",
    "        sens_pred = θ_s(X, A_p)\n",
    "        L += F.cross_entropy(sens_pred[g0], T_s[g0]) \\\n",
    "            - F.cross_entropy(sens_pred[gX], T_s[gX])\n",
    "        \n",
    "        utility_pred = θ_u(X, A_p)\n",
    "        L -= F.cross_entropy(utility_pred, T_u)\n",
    "\n",
    "        A_grad = torch.autograd.grad(L, A_p)[0]\n",
    "        M = truncate(M + ((lr * A_grad) / (epoch + 1)), A)\n",
    "        # M = scale(M, ε)\n",
    "        M = utils.projection(M, ε)\n",
    "\n",
    "        A_p = xor(A, discretize(M)).to(device).requires_grad_(True)\n",
    "        θ_s.fit(X, A_p, T_s, train_mask, val_mask, train_iters=1)\n",
    "        θ_u.fit(X, A_p, T_u, train_mask, val_mask, train_iters=1)\n",
    "\n",
    "        t.set_postfix({\n",
    "            \"loss\": L.item(),\n",
    "            # \"edges modified\": (A_p.cpu() - A).abs().sum().item()\n",
    "        })\n",
    "    \n",
    "    return A_p.requires_grad_(False)\n",
    "\n",
    "budget = (adj.shape[0]) * args.budget_pct\n",
    "locked_adj = SLL(adj, feat, g0, T_s, T_u, budget, 100, lr=10, train_mask=train_mask, val_mask=val_mask, device=device)\n",
    "evaluate(feat, locked_adj, T_s, g0, train_mask, val_mask, device)\n",
    "evaluate(feat, locked_adj, T_u, g0, train_mask, val_mask, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLL Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(996.), 617522)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SamplingMatrix:\n",
    "    def __init__(self, num_nodes: int, g0: torch.Tensor) -> None:\n",
    "        self.g0_idx = g0.nonzero()\n",
    "        self.gX_idx = (~g0).nonzero()\n",
    "        self.n = num_nodes\n",
    "        self.r00 = 1/3\n",
    "        self.r0X = 1/3\n",
    "        self.rXX = 1/3\n",
    "        pass\n",
    "\n",
    "    def update_ratio(self, A_grad, ema_k=3):\n",
    "        sum_00 = A_grad[self.g0_idx, self.g0_idx].sum()\n",
    "        sum_XX = A_grad[self.gX_idx, self.gX_idx].sum()\n",
    "        sum_0X = A_grad.sum() - sum_00 - sum_XX\n",
    "        total = sum_00 + sum_0X + sum_XX\n",
    "        self.r00 = ((ema_k - 1) * self.r00 +  (sum_00 / total)) / ema_k\n",
    "        self.r0X = ((ema_k - 1) * self.r0X +  (sum_0X / total)) / ema_k\n",
    "        self.rXX = ((ema_k - 1) * self.rXX +  (sum_XX / total)) / ema_k\n",
    "        total = self.r00 + self.r0X + self.rXX\n",
    "        self.r00 = self.r00 / total\n",
    "        self.r0X = self.r0X / total\n",
    "        self.rXX = self.rXX / total\n",
    "\n",
    "    def get_sample(self, sample_size: int) -> torch.Tensor:\n",
    "        num_00 = int(self.r00 * sample_size)\n",
    "        g00 = torch.cat(\n",
    "            [self.g0_idx[torch.randint(0, self.g0_idx.shape[0], [num_00])], \n",
    "             self.g0_idx[torch.randint(0, self.g0_idx.shape[0], [num_00])]]\n",
    "             , 1)\n",
    "        num_0X = int(self.r0X * sample_size)\n",
    "        g0X = torch.cat(\n",
    "            [self.g0_idx[torch.randint(0, self.g0_idx.shape[0], [num_0X])], \n",
    "             self.gX_idx[torch.randint(0, self.gX_idx.shape[0], [num_0X])]]\n",
    "             , 1)\n",
    "        num_XX = int(self.rXX * sample_size)\n",
    "        gXX = torch.cat(\n",
    "            [self.gX_idx[torch.randint(0, self.gX_idx.shape[0], [num_XX])], \n",
    "             self.gX_idx[torch.randint(0, self.gX_idx.shape[0], [num_XX])]]\n",
    "             , 1)\n",
    "        \n",
    "        return torch.cat([g00, g0X, gXX], 0).t()\n",
    "\n",
    "sampling = SamplingMatrix(adj.shape[0], g0)\n",
    "sample_size = int(adj.shape[0] * adj.shape[1] * 0.1)\n",
    "sample = sampling.get_sample(sample_size)\n",
    "adj[sample[0], sample[1]].sum(), sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLL_G(\n",
    "        A: torch.Tensor, \n",
    "        X:torch.Tensor, \n",
    "        g0: torch.Tensor, \n",
    "        T_s: torch.Tensor, \n",
    "        T_u: torch.Tensor, \n",
    "        ε: int,\n",
    "        epochs: int,\n",
    "        sample_ct: int,\n",
    "        sample_size: int,\n",
    "        lr: float,\n",
    "        train_mask: torch.Tensor,\n",
    "        val_mask: torch.Tensor,\n",
    "        device='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    T_s is sensitive classification task\n",
    "    T_u is utility classification task\n",
    "    g0 is array of boolean representing protected nodes.\n",
    "    \"\"\"\n",
    "    gX = ~g0\n",
    "    X = X.to(device)\n",
    "    T_s = T_s.to(device)\n",
    "    T_u = T_u.to(device)\n",
    "    A = A.to(device)\n",
    "\n",
    "    M = torch.zeros_like(A).float()\n",
    "    θ_s = GCN(nfeat=X.shape[1], nclass=T_s.max().item()+1, nhid=32, device=device).to(device)\n",
    "    θ_u = GCN(nfeat=X.shape[1], nclass=T_u.max().item()+1, nhid=32, device=device).to(device)\n",
    "\n",
    "    t = tqdm(range(epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    A_p = torch.zeros_like(A) # Initialize modified adj\n",
    "    sampling_matrix = SamplingMatrix(A.shape[0], g0)\n",
    "\n",
    "    for epoch in t:\n",
    "        # A_p = xor(A, discretize(M, ε)).to(device).requires_grad_(True) # To clear graident of modified adj\n",
    "        cts = torch.zeros_like(A, dtype=torch.int)\n",
    "        A_grad = torch.zeros_like(A, dtype=torch.float)\n",
    "        c_L = 0\n",
    "\n",
    "        for _ in range(sample_ct):\n",
    "            idx = sampling_matrix.get_sample(sample_size)\n",
    "\n",
    "            sample = A_p[idx[0], idx[1]].clone().detach().requires_grad_(True).to(device)\n",
    "            A_p[idx[0], idx[1]] = sample\n",
    "\n",
    "            L = 0\n",
    "            sens_pred = θ_s(X, A_p)\n",
    "            utility_pred = θ_u(X, A_p)\n",
    "            L += F.cross_entropy(sens_pred[g0], T_s[g0]) \\\n",
    "                - F.cross_entropy(sens_pred[gX], T_s[gX])\n",
    "            L -= F.cross_entropy(utility_pred, T_u)\n",
    "\n",
    "            grad = torch.autograd.grad(L, sample)[0]\n",
    "            cts[idx[0], idx[1]] += 1\n",
    "            A_grad[idx[0], idx[1]] += grad\n",
    "            c_L += L.item()\n",
    "\n",
    "        A_grad = torch.div(A_grad, cts)\n",
    "        A_grad[A_grad != A_grad] = 0\n",
    "\n",
    "        sampling_matrix.update_ratio(A_grad)\n",
    "        M = truncate(M + ((lr * A_grad) / (epoch + 1)), A)\n",
    "        # M = scale(M, ε)\n",
    "        M = utils.projection(M, ε)\n",
    "\n",
    "        A_p = xor(A, discretize(M)).to(device)\n",
    "        θ_s.fit(X, A_p, T_s, train_mask, val_mask, train_iters=1)\n",
    "        θ_u.fit(X, A_p, T_u, train_mask, val_mask, train_iters=1)\n",
    "\n",
    "        t.set_postfix({\n",
    "            \"loss\": c_L,\n",
    "            # \"edges modified\": (A_p.cpu() - A).abs().sum().item()\n",
    "        })\n",
    "    \n",
    "    return A_p.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLL_G2(\n",
    "        A: torch.Tensor, \n",
    "        X:torch.Tensor, \n",
    "        g0: torch.Tensor, \n",
    "        T_s: torch.Tensor, \n",
    "        T_u: torch.Tensor, \n",
    "        ε: int,\n",
    "        epochs: int,\n",
    "        sample_ct: int,\n",
    "        sample_size: int,\n",
    "        lr: float,\n",
    "        device='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    T_s is sensitive classification task\n",
    "    T_u is utility classification task\n",
    "    g0 is array of boolean representing protected nodes.\n",
    "    \"\"\"\n",
    "    gX = ~g0\n",
    "    X = X.to(device)\n",
    "    T_s = T_s.to(device)\n",
    "    T_u = T_u.to(device)\n",
    "    A = A.to(device)\n",
    "\n",
    "    M = torch.zeros_like(A).float()\n",
    "    θ_s = GCN(nfeat=X.shape[1], nclass=T_s.max().item()+1, nhid=32, device=device).to(device)\n",
    "    θ_u = GCN(nfeat=X.shape[1], nclass=T_u.max().item()+1, nhid=32, device=device).to(device)\n",
    "\n",
    "    t = tqdm(range(epochs), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')\n",
    "    A_p = torch.zeros_like(A).to(device).requires_grad_(True) # Initialize modified adj\n",
    "    sampling_matrix = SamplingMatrix(A.shape[0], g0)\n",
    "\n",
    "    for epoch in t:\n",
    "        # A_p = xor(A, discretize(M, ε)).to(device).requires_grad_(True) # To clear graident of modified adj\n",
    "        # cts = torch.zeros_like(A, dtype=torch.int)\n",
    "\n",
    "        L = 0\n",
    "        sens_pred = θ_s(X, A_p)\n",
    "        L += F.cross_entropy(sens_pred[g0], T_s[g0]) \\\n",
    "            - F.cross_entropy(sens_pred[gX], T_s[gX])\n",
    "        \n",
    "        utility_pred = θ_u(X, A_p)\n",
    "        L -= F.cross_entropy(utility_pred, T_u)\n",
    "\n",
    "        temp_grad = torch.autograd.grad(L, A_p)[0]\n",
    "        idx = sampling_matrix.get_sample(sample_size * num_samples)\n",
    "        # cts[idx[0], idx[1]] += 1\n",
    "        A_grad = torch.zeros_like(A, dtype=torch.float)\n",
    "        A_grad[idx[0], idx[1]] = temp_grad[idx[0], idx[1]]\n",
    "        # A_grad = torch.div(A_grad, cts)\n",
    "        # A_grad[A_grad != A_grad] = 0\n",
    "        sampling_matrix.update_ratio(A_grad)\n",
    "\n",
    "        M = truncate(M + ((lr * A_grad) / (epoch + 1)), A)\n",
    "        # M = scale(M, ε)\n",
    "        M = utils.projection(M, ε)\n",
    "\n",
    "        A_p = xor(A, discretize(M)).to(device).requires_grad_(True)\n",
    "        θ_s.fit(X, A_p, T_s, train_mask, idx_val, train_iters=1)\n",
    "        θ_u.fit(X, A_p, T_u, train_mask, idx_val, train_iters=1)\n",
    "\n",
    "        t.set_postfix({\n",
    "            \"loss\": L.item(),\n",
    "            # \"edges modified\": (A_p.cpu() - A).abs().sum().item()\n",
    "        })\n",
    "    \n",
    "    return A_p.requires_grad_(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.66it/s, loss=113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G0: 50.29%\n",
      "GX: 81.64%\n",
      "G0: 99.42%\n",
      "GX: 99.39%\n"
     ]
    }
   ],
   "source": [
    "budget = (adj.shape[0]) * args.budget_pct\n",
    "sample_size = int(adj.shape[0] * adj.shape[1] * 0.001)\n",
    "locked_adj = SLL_G(adj, feat, g0, T_s, T_u, budget, sample_ct=10, sample_size=sample_size, epochs=30, lr=100, train_mask=train_mask, val_mask=val_mask, device=device)\n",
    "evaluate(feat, locked_adj, T_s, g0, train_mask, val_mask, device)\n",
    "evaluate(feat, locked_adj, T_u, g0, train_mask, val_mask, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_c116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
